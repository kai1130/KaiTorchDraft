{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55de1ec3",
   "metadata": {},
   "source": [
    "# Notebook 02 - Reverse-mode Autodiff & Backpropogation\n",
    "\n",
    "### Recapping previous notebooks\n",
    "__notebook 0__\n",
    "\n",
    "1) The gradient is how changes in an input variable affects the output.\n",
    "\n",
    "2) We can break down complex functions into smaller parts and \"chain\" them together.\n",
    "\n",
    "__notebook 1__\n",
    "\n",
    "1) We can convert a complex function into a composite function, made up of a chain of simple operations\n",
    "\n",
    "2) We can model a composite function as a simple feed forward neural net with a graph structure, and calculate the result using a forward pass."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12fa980",
   "metadata": {},
   "source": [
    "__So we've essentially built an unnecessary complicated version of a simple calculator__ - but we did this for a reason.\n",
    "\n",
    "A calculator is good for taking inputs and spitting out an output. A neural network is good at taking input and output pairs, and iteratively tweaking its weights so that when it takes an input, it spits out the output that we want.\n",
    "\n",
    "In this notebook, we'll bridge the gap and turn our calculator into a neural network in a few steps:\n",
    "\n",
    "1) Understanding the chain rule\n",
    "\n",
    "2) Defining the derivatives of our base operations\n",
    "\n",
    "3) Implementing reverse-mode automatic differentiation\n",
    "\n",
    "4) Updating weights through backpropogation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4a3a3b",
   "metadata": {},
   "source": [
    "# The Chain Rule\n",
    "\n",
    "__The chain rule is a method of calculating the gradients of a composite function.__\n",
    "\n",
    "This rule is particularly integral to neural networks as it takes advantage of the property that neural networks, which are very complicated functions, can be broken down into a chain of primitive operations such as addition and multiplication.\n",
    "\n",
    "This is the chain rule:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31306cf8",
   "metadata": {},
   "source": [
    "$$ \\frac{dL}{dx} = \\frac{dL}{dy} \\cdot \\frac{dy}{dx}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462940fc",
   "metadata": {},
   "source": [
    "$L, y, x$ are variables, and I chose those letters to represent different parts of the neural network\n",
    "- $L$ is the loss value\n",
    "- $y$ is the output of a node\n",
    "- $x$ is an input of a node\n",
    "\n",
    "If we want to train a network, we need to adjust its weights to minimize the loss (\"error\") of a model. We want to adjust the value of each variable $x$ in a way that will minimize $L$.\n",
    "\n",
    "How each variable affects the loss function is notated as:\n",
    "\n",
    "$$ \\frac{dL}{dx} $$\n",
    "\n",
    "However, there might be many nested functions between our variable $x$ and the final output $L$. This might seem like a lot of added complexity, but the chain rule allows us to take advantage of this property.\n",
    "\n",
    "__Chaining derivatives__\n",
    "\n",
    "Let's say input $x$ is used to calculate output $y$, which is used to calculate loss $L$.\n",
    "\n",
    "$$ x \\Rightarrow y \\Rightarrow L $$\n",
    "\n",
    "To calculate the derivative of $L$ with respect to $x$, we can calculate the derivative of $L$ with respect to $y$, multiplied by the derivative of $y$ with respect to $x$.\n",
    "\n",
    "$$ \\frac{dL}{dx} = \\frac{dL}{dy} \\cdot \\frac{dy}{dx}$$\n",
    "\n",
    "Now let's say $w$ is used to calculate $x$, which is used to calculate $y$, which is used to calculate $z$, which is used to calculate $L$.\n",
    "\n",
    "$$ w \\Rightarrow x \\Rightarrow y \\Rightarrow z \\Rightarrow L $$\n",
    "\n",
    "The chain rule lets us find how $w$ affects $L$ by calculating:\n",
    "\n",
    "$$ \\frac{dL}{dw} = \\frac{dL}{dz} \\cdot \\frac{dz}{dy} \\cdot \\frac{dy}{dx} \\cdot \\frac{dx}{dw}$$\n",
    "\n",
    "__See how for longer sequences, we just create a longer chain of derivative multiplications?__ and since we are using a chain of primitive operations, each of these derivatives is almost trivial. Let's take an example:\n",
    "\n",
    "$$ L = (((((a ^ 2) * 6) - 4) / 3) + 5 $$\n",
    "\n",
    "can be broken down as\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "&L = e + 5\\\\\n",
    "&e = d / 3\\\\\n",
    "&d = c - 4\\\\\n",
    "&c = b * 6\\\\\n",
    "&b = a ^ 2\\\\\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "chaining the derivatives:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "\\frac{dL}{da} &= \\frac{dL}{de} \\cdot \\frac{de}{dd} \\cdot \\frac{dd}{dc} \\cdot \\frac{dc}{db} \\cdot \\frac{db}{da} \\\\\n",
    "&= 1 \\cdot \\frac{1}{3} \\cdot  1 \\cdot 6 \\cdot 2a\\\\\n",
    "&= 4a\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "double checking our result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd053a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(a):\n",
    "    return (((((a**2) * 6) - 4) / 3) + 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ac18181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n"
     ]
    }
   ],
   "source": [
    "eps = 1e-8\n",
    "a = 1\n",
    "rise = f(a+eps) - f(a)\n",
    "run = (a+eps)-a\n",
    "gradient = rise/run\n",
    "print(gradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e561f9f",
   "metadata": {},
   "source": [
    "# Reverse-mode Automatic Differentiation\n",
    "\n",
    "Hopefully my explanation of the chain rule makes sense as we move into reverse-mode autodiff. This term might sound complicated, but its basically the chain rule, where we start from the Loss value and recursively apply the chain rule until we find the gradient of every weight and bias in the network. Let me try to illustrate this idea in a simplified way.\n",
    "\n",
    "__Let's say our forward pass is like this:__\n",
    "\n",
    "$$ x \\Rightarrow y \\Rightarrow L $$\n",
    "\n",
    "where $x$ is used to calculate $y$, is used to calculate loss $L$.\n",
    "\n",
    "__In the backward pass:__\n",
    "1) We start from loss $L$, and we see that it used $y$\n",
    "\n",
    "  - Find the gradient of $y$ using $\\frac{dL}{dy}$\n",
    "\n",
    "2) We see that $y$ used variable $x$\n",
    "\n",
    "  - Find the gradient of $\\frac{dL}{dx}$ by calculating $\\frac{dL}{dy} \\frac{dy}{dx}$\n",
    "  - Since we already calculated $\\frac{dL}{dy}$ in the first step, really we just need to calculate $\\frac{dy}{dx}$ and multiply the two together\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4708fc23",
   "metadata": {},
   "source": [
    "# Implementation\n",
    "\n",
    "Lets add reverse-mode autodiff to KaiTorch, recall our `Scalar` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "66358a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaitorch/core.py\n",
    "\n",
    "import math\n",
    "\n",
    "class Scalar:\n",
    "\n",
    "    def __init__(self, data, _in=(), _op=''):\n",
    "        self.data = data\n",
    "        self.grad = 0.0 # hi :)\n",
    "\n",
    "        self._backward = lambda: None  # hi :)\n",
    "        self._prev = set(_in)\n",
    "        self._op = _op\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f'Value(data={self.data})'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb681d0",
   "metadata": {},
   "source": [
    "Recall our 5 base operations:\n",
    "- Addition\n",
    "- Multiplication\n",
    "- Exponentiation\n",
    "- Natural Exponentiation\n",
    "- Natural Log\n",
    "\n",
    "Let's define the derivative of each one by adding a `_backward()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1864468c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaitorch/core.py\n",
    "\n",
    "# Addition\n",
    "def __add__(a, b):\n",
    "\n",
    "    a = a if isinstance(a, Scalar) else Scalar(a)\n",
    "    b = b if isinstance(b, Scalar) else Scalar(b)\n",
    "\n",
    "    # Calculation: y = a + b\n",
    "    def _forward():\n",
    "        _a = a.data\n",
    "        _b = b.data\n",
    "        _y = _a + _b\n",
    "        return Scalar(_y, _in=(a, b), _op='+')\n",
    "    y = _forward()\n",
    "\n",
    "    # Derivative: dy/da = 1\n",
    "    # Chain Rule: dL/da = dL/dy * dy/da\n",
    "    #                   = dL/dy\n",
    "    def _backward():\n",
    "        a.grad += y.grad\n",
    "        b.grad += y.grad\n",
    "    y._backward = _backward\n",
    "\n",
    "    return y\n",
    "\n",
    "Scalar.__add__ = __add__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6639c2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaitorch/core.py\n",
    "\n",
    "# Multiplication\n",
    "def __mul__(a, b):\n",
    "\n",
    "    a = a if isinstance(a, Scalar) else Scalar(a)\n",
    "    b = b if isinstance(b, Scalar) else Scalar(b)\n",
    "\n",
    "    # Calculation: y = a * b\n",
    "    def _forward():\n",
    "        _a = a.data\n",
    "        _b = b.data\n",
    "        _y = _a * _b\n",
    "        return Scalar(_y, _in=(a, b), _op='*')\n",
    "    y = _forward()\n",
    "\n",
    "    # Derivative: dy/da = b\n",
    "    # Chain Rule: dL/da = dL/dy * dy/da\n",
    "    #                   = dL/dy * b\n",
    "    def _backward():\n",
    "        a.grad += y.grad * b.data\n",
    "        b.grad += y.grad * a.data\n",
    "    y._backward = _backward\n",
    "\n",
    "    return y\n",
    "\n",
    "Scalar.__mul__ = __mul__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f739fb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaitorch/core.py\n",
    "\n",
    "# Exponentiation\n",
    "def __pow__(a, b):\n",
    "\n",
    "    assert isinstance(b, (int, float)), \"Exponent is not int/float\"\n",
    "\n",
    "    # Calculation: y = a ** b\n",
    "    def _forward():\n",
    "        _a = a.data\n",
    "        _y = (_a + 1e-7) ** b  # don't divide by 0 :)\n",
    "        return Scalar(_y, _in=(a,), _op=f'**{b}')\n",
    "    y = _forward()\n",
    "\n",
    "    # Derivative: dy/da = b * (a ** (b-1))\n",
    "    # Chain Rule: dL/da = dL/dy * dy/da\n",
    "    #                   = dL/dy * b * (a ** (b-1))\n",
    "    def _backward():\n",
    "        a.grad += y.grad * (b * a.data ** (b - 1))\n",
    "    y._backward = _backward\n",
    "\n",
    "    return y\n",
    "\n",
    "Scalar.__pow__ = __pow__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b8e8c25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaitorch/core.py\n",
    "\n",
    "# Natural Exponentiation\n",
    "def exp(a):\n",
    "\n",
    "    # Calculation: y = e ** a\n",
    "    def _forward():\n",
    "        _a = a.data\n",
    "        _y = math.exp(_a)\n",
    "        return Scalar(_y, _in=(a, ), _op='exp')\n",
    "    y = _forward()\n",
    "\n",
    "    # Derivative: dy/da = y\n",
    "    # Chain Rule: dL/da = dL/dy * dy/da\n",
    "    #                   = dL/dy * y\n",
    "    def _backward():\n",
    "        a.grad += y.grad * y.data\n",
    "    y._backward = _backward\n",
    "\n",
    "    return y\n",
    "\n",
    "Scalar.exp = exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "98950980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaitorch/core.py\n",
    "\n",
    "# Natural Log\n",
    "def log(a):\n",
    "\n",
    "    # Calculation: y = ln(a)\n",
    "    def _forward():\n",
    "        _a = a.data\n",
    "        _y = math.log(_a + 1e-8)\n",
    "\n",
    "        return Scalar(_y, _in=(a, ), _op='ln')\n",
    "    y = _forward()\n",
    "\n",
    "    # Derivative: dy/da = 1/a * a'\n",
    "    # Chain Rule: dL/da = dL/dy * dy/da * a'\n",
    "    #                   = dL/dy * 1/a * a'\n",
    "    def _backward():\n",
    "        a.grad += y.grad * ((a.data + 1e-8).__pow__(-1))\n",
    "    y._backward = _backward\n",
    "\n",
    "    return y\n",
    "\n",
    "Scalar.log = log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b362e014",
   "metadata": {},
   "source": [
    "You might have noticed that the `_forward()` is automatically called, but `_backward` isn't. This is because we don't want to/can't calculate the derivatives during the forward pass. We just tell the `Scalar` to remember how to calculate the derivative, and then call it during the backward pass."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a999f579",
   "metadata": {},
   "source": [
    "__What about subtraction, division, and negatives?__\n",
    "\n",
    "Recall that the calculation of these operations can be achieved by chaining the `_foward()` calculations of the base operators.\n",
    "\n",
    "Similarly, the derivative of these operations can be achieved by chaining the `_backward()` calculations of the base operators.\n",
    "\n",
    "And just as we can calculate the value of every node during the forward pass by starting from our inputs and propogating calculation results forward, we can calculate the derivative of every node during the backward pass by starting from our loss value and propogating the gradients backward!\n",
    "\n",
    "Copying over all the other class methods from last notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1de71378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaitorch/core.py\n",
    "\n",
    "def __radd__(a, b):\n",
    "\n",
    "    # b + a = a + b\n",
    "    return a.__add__(b)\n",
    "\n",
    "Scalar.__radd__ = __radd__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a552d06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaitorch/core.py\n",
    "\n",
    "def __rmul__(a, b):\n",
    "\n",
    "    # b * a = a * b\n",
    "    return a.__mul__(b)\n",
    "\n",
    "Scalar.__rmul__ = __rmul__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cb3abaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaitorch/core.py\n",
    "\n",
    "def __neg__(a):\n",
    "\n",
    "    # -a = a * -1\n",
    "    return a.__mul__(-1)\n",
    "\n",
    "Scalar.__neg__ = __neg__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b760ce73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaitorch/core.py\n",
    "\n",
    "def __sub__(a, b):\n",
    "\n",
    "    # a - b = a + (b * -1)\n",
    "    return a.__add__(b.__neg__())\n",
    "\n",
    "def __rsub__(a, b):\n",
    "\n",
    "    # b - a = (a * -1) + b\n",
    "    return (a.__neg__()).__add__(b)\n",
    "\n",
    "Scalar.__sub__ = __sub__\n",
    "Scalar.__rsub__ = __rsub__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "889efe96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaitorch/core.py\n",
    "\n",
    "def __truediv__(a, b):\n",
    "\n",
    "    # a / b = a * (b ** -1)\n",
    "    return a.__mul__((b + 1e-8).__pow__(-1)) # Avoid Division by 0\n",
    "\n",
    "def __rtruediv__(a, b):\n",
    "\n",
    "    # b / a = b * (a ** -1)\n",
    "    return Scalar(b).__mul__((a + 1e-8).__pow__(-1)) # Avoid Division by 0\n",
    "\n",
    "Scalar.__truediv__ = __truediv__\n",
    "Scalar.__rtruediv__ = __rtruediv__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f5c8ce",
   "metadata": {},
   "source": [
    "# Topological Sort\n",
    "\n",
    "The last piece to finishing our implementation of reverse-mode autodiff is knowing in what order to calculate the gradients. We need to make sure that if \n",
    "\n",
    "$$ x \\Rightarrow y \\Rightarrow L $$\n",
    "\n",
    "That we calculate the derivative of $y$ before we calculate the derivative of $x$, since when using the chain rule, $dx$ depends on $dy$.\n",
    "\n",
    "The solution to this is a topological sort, where in a graph consisting of edges from `node X` to `node Y`, `X` always comes before `Y` in the ordering. With the above example, a topological sort would (trivially) return `[x, y, L]`.\n",
    "\n",
    "Since we're doing a backward pass and we want to start from L, we simply reverse the topological sort to get the order in which we should calculate the derivatives, such that for each `node X` that is used to calculate `node Y`, `dY` is calculated before `dX`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "45612364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaitorch/core.py\n",
    "\n",
    "def backward(self):\n",
    "\n",
    "    topo = []\n",
    "    visited = set()\n",
    "\n",
    "    def build_topo(v):\n",
    "        if v not in visited:\n",
    "            visited.add(v)\n",
    "            for child in v._prev:\n",
    "                build_topo(child)\n",
    "            topo.append(v)\n",
    "    build_topo(self)\n",
    "\n",
    "    self.grad = 1.0\n",
    "    for node in reversed(topo):\n",
    "        node._backward()\n",
    "\n",
    "Scalar.backward = backward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0076bd04",
   "metadata": {},
   "source": [
    "__That's it! 🥳 -__ we have all the ingredients we need to calculate the gradient of every node in the network now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79642b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaitorch.graph import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "51e61975",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = Scalar(2.0)\n",
    "w1 = Scalar(-3.0)\n",
    "\n",
    "x2 = Scalar(0.0)\n",
    "w2 = Scalar(1.0)\n",
    "\n",
    "b = Scalar(13.5)\n",
    "\n",
    "x1w1 = x1*w1; x1w1.label = 'x1*w1'\n",
    "x2w2 = x2*w2; x2w2.label = 'x2*w2'\n",
    "\n",
    "x1w1x2w2 = x1w1 + x2w2; x1w1x2w2.label = 'x1*w1 + x2*w2'\n",
    "\n",
    "n = x1w1x2w2+b; n.label = 'n'\n",
    "\n",
    "n.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "04d7e3fe",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 6.0.1 (20220911.1526)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"398pt\" height=\"520pt\"\n",
       " viewBox=\"0.00 0.00 397.50 520.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 516)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-516 393.5,-516 393.5,4 -4,4\"/>\n",
       "<!-- 140509206202880 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>140509206202880</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"50,-155.5 50,-201.5 137,-201.5 137,-155.5 50,-155.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"93.5\" y=\"-186.3\" font-family=\"Times,serif\" font-size=\"14.00\">data 13.5000</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"50,-178.5 137,-178.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"93.5\" y=\"-163.3\" font-family=\"Times,serif\" font-size=\"14.00\">grad 1.0000</text>\n",
       "</g>\n",
       "<!-- 140509206110016+ -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>140509206110016+</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"145.5\" cy=\"-101\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"145.5\" y=\"-97.3\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n",
       "</g>\n",
       "<!-- 140509206202880&#45;&gt;140509206110016+ -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>140509206202880&#45;&gt;140509206110016+</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M108.82,-155.26C115.09,-146.16 122.35,-135.61 128.76,-126.31\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"131.79,-128.08 134.58,-117.86 126.02,-124.11 131.79,-128.08\"/>\n",
       "</g>\n",
       "<!-- 140509206200864 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>140509206200864</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"0,-465.5 0,-511.5 85,-511.5 85,-465.5 0,-465.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"42.5\" y=\"-496.3\" font-family=\"Times,serif\" font-size=\"14.00\">data &#45;3.0000</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"0,-488.5 85,-488.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"42.5\" y=\"-473.3\" font-family=\"Times,serif\" font-size=\"14.00\">grad 2.0000</text>\n",
       "</g>\n",
       "<!-- 140509206202544* -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>140509206202544*</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"146.5\" cy=\"-411\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"146.5\" y=\"-407.3\" font-family=\"Times,serif\" font-size=\"14.00\">*</text>\n",
       "</g>\n",
       "<!-- 140509206200864&#45;&gt;140509206202544* -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>140509206200864&#45;&gt;140509206202544*</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M72.86,-465.46C87.95,-454.5 106.01,-441.4 120.46,-430.9\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"122.9,-433.46 128.94,-424.75 118.79,-427.79 122.9,-433.46\"/>\n",
       "</g>\n",
       "<!-- 140509206203888 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>140509206203888</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"103.5,-465.5 103.5,-511.5 189.5,-511.5 189.5,-465.5 103.5,-465.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"146.5\" y=\"-496.3\" font-family=\"Times,serif\" font-size=\"14.00\">data 2.0000</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"103.5,-488.5 189.5,-488.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"146.5\" y=\"-473.3\" font-family=\"Times,serif\" font-size=\"14.00\">grad &#45;3.0000</text>\n",
       "</g>\n",
       "<!-- 140509206203888&#45;&gt;140509206202544* -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>140509206203888&#45;&gt;140509206202544*</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M146.5,-465.26C146.5,-457.18 146.5,-447.96 146.5,-439.49\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"150,-439.3 146.5,-429.3 143,-439.3 150,-439.3\"/>\n",
       "</g>\n",
       "<!-- 140509206201008 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>140509206201008</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"207.5,-465.5 207.5,-511.5 289.5,-511.5 289.5,-465.5 207.5,-465.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"248.5\" y=\"-496.3\" font-family=\"Times,serif\" font-size=\"14.00\">data 0.0000</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"207.5,-488.5 289.5,-488.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"248.5\" y=\"-473.3\" font-family=\"Times,serif\" font-size=\"14.00\">grad 1.0000</text>\n",
       "</g>\n",
       "<!-- 140509206084384* -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>140509206084384*</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"248.5\" cy=\"-411\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"248.5\" y=\"-407.3\" font-family=\"Times,serif\" font-size=\"14.00\">*</text>\n",
       "</g>\n",
       "<!-- 140509206201008&#45;&gt;140509206084384* -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>140509206201008&#45;&gt;140509206084384*</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M248.5,-465.26C248.5,-457.18 248.5,-447.96 248.5,-439.49\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"252,-439.3 248.5,-429.3 245,-439.3 252,-439.3\"/>\n",
       "</g>\n",
       "<!-- 140509206202544 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>140509206202544</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"104,-310.5 104,-356.5 189,-356.5 189,-310.5 104,-310.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"146.5\" y=\"-341.3\" font-family=\"Times,serif\" font-size=\"14.00\">data &#45;6.0000</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"104,-333.5 189,-333.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"146.5\" y=\"-318.3\" font-family=\"Times,serif\" font-size=\"14.00\">grad 1.0000</text>\n",
       "</g>\n",
       "<!-- 140509206085536+ -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>140509206085536+</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"197.5\" cy=\"-256\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"197.5\" y=\"-252.3\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n",
       "</g>\n",
       "<!-- 140509206202544&#45;&gt;140509206085536+ -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>140509206202544&#45;&gt;140509206085536+</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M161.53,-310.26C167.67,-301.16 174.8,-290.61 181.08,-281.31\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"184.09,-283.11 186.79,-272.86 178.29,-279.19 184.09,-283.11\"/>\n",
       "</g>\n",
       "<!-- 140509206202544*&#45;&gt;140509206202544 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>140509206202544*&#45;&gt;140509206202544</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M146.5,-392.87C146.5,-385.18 146.5,-375.83 146.5,-366.9\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"150,-366.73 146.5,-356.73 143,-366.73 150,-366.73\"/>\n",
       "</g>\n",
       "<!-- 140509206084384 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>140509206084384</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"207.5,-310.5 207.5,-356.5 289.5,-356.5 289.5,-310.5 207.5,-310.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"248.5\" y=\"-341.3\" font-family=\"Times,serif\" font-size=\"14.00\">data 0.0000</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"207.5,-333.5 289.5,-333.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"248.5\" y=\"-318.3\" font-family=\"Times,serif\" font-size=\"14.00\">grad 1.0000</text>\n",
       "</g>\n",
       "<!-- 140509206084384&#45;&gt;140509206085536+ -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>140509206084384&#45;&gt;140509206085536+</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M233.47,-310.26C227.33,-301.16 220.2,-290.61 213.92,-281.31\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"216.71,-279.19 208.21,-272.86 210.91,-283.11 216.71,-279.19\"/>\n",
       "</g>\n",
       "<!-- 140509206084384*&#45;&gt;140509206084384 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>140509206084384*&#45;&gt;140509206084384</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M248.5,-392.87C248.5,-385.18 248.5,-375.83 248.5,-366.9\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"252,-366.73 248.5,-356.73 245,-366.73 252,-366.73\"/>\n",
       "</g>\n",
       "<!-- 140509206110016 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>140509206110016</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"104.5,-0.5 104.5,-46.5 186.5,-46.5 186.5,-0.5 104.5,-0.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"145.5\" y=\"-31.3\" font-family=\"Times,serif\" font-size=\"14.00\">data 7.5000</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"104.5,-23.5 186.5,-23.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"145.5\" y=\"-8.3\" font-family=\"Times,serif\" font-size=\"14.00\">grad 1.0000</text>\n",
       "</g>\n",
       "<!-- 140509206110016+&#45;&gt;140509206110016 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>140509206110016+&#45;&gt;140509206110016</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M145.5,-82.87C145.5,-75.18 145.5,-65.83 145.5,-56.9\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"149,-56.73 145.5,-46.73 142,-56.73 149,-56.73\"/>\n",
       "</g>\n",
       "<!-- 140509206085536 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>140509206085536</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"155,-155.5 155,-201.5 240,-201.5 240,-155.5 155,-155.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"197.5\" y=\"-186.3\" font-family=\"Times,serif\" font-size=\"14.00\">data &#45;6.0000</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"155,-178.5 240,-178.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"197.5\" y=\"-163.3\" font-family=\"Times,serif\" font-size=\"14.00\">grad 1.0000</text>\n",
       "</g>\n",
       "<!-- 140509206085536&#45;&gt;140509206110016+ -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>140509206085536&#45;&gt;140509206110016+</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M182.18,-155.26C175.91,-146.16 168.65,-135.61 162.24,-126.31\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"164.98,-124.11 156.42,-117.86 159.21,-128.08 164.98,-124.11\"/>\n",
       "</g>\n",
       "<!-- 140509206085536+&#45;&gt;140509206085536 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>140509206085536+&#45;&gt;140509206085536</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M197.5,-237.87C197.5,-230.18 197.5,-220.83 197.5,-211.9\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"201,-211.73 197.5,-201.73 194,-211.73 201,-211.73\"/>\n",
       "</g>\n",
       "<!-- 140509206200816 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>140509206200816</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"307.5,-465.5 307.5,-511.5 389.5,-511.5 389.5,-465.5 307.5,-465.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"348.5\" y=\"-496.3\" font-family=\"Times,serif\" font-size=\"14.00\">data 1.0000</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"307.5,-488.5 389.5,-488.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"348.5\" y=\"-473.3\" font-family=\"Times,serif\" font-size=\"14.00\">grad 0.0000</text>\n",
       "</g>\n",
       "<!-- 140509206200816&#45;&gt;140509206084384* -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>140509206200816&#45;&gt;140509206084384*</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M319.31,-465.46C304.89,-454.57 287.66,-441.57 273.81,-431.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"275.77,-428.2 265.68,-424.97 271.55,-433.79 275.77,-428.2\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7fcad950f6a0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_model(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c5c984",
   "metadata": {},
   "source": [
    "# Backpropogation\n",
    "\n",
    "Backpropogation is everything we've done so far - calculating the gradients of every parameter/weight - with the added step of updating the weights of our network. There are many ways to do this which we'll cover in the following notebooks.\n",
    "\n",
    "But before we do this, we'll want to to first implement a functional neural network with Dense layers, and cover loss functions and optimization.\n",
    "\n",
    "keep reading $\\Rightarrow$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
